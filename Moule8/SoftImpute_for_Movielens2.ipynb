{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nunez350/DataScienceAndAnalytics/blob/main/Moule8/SoftImpute_for_Movielens2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b3c46e94",
      "metadata": {
        "id": "b3c46e94"
      },
      "source": [
        "#  The MovieLens Dataset\n",
        "\n",
        "[MovieLens](https://movielens.org/) is a non-commercial web-based movie recommender system, created in 1997 by GroupLens, a research lab at the University of Minnesota, in order to gather movie rating data for research purposes.\n",
        "\n",
        "\n",
        "## Getting the Data\n",
        "\n",
        "\n",
        "The MovieLens dataset is hosted by the [GroupLens](https://grouplens.org/datasets/movielens/) website. Several versions are available. We will use the latest smallest dataset released from [link](https://files.grouplens.org/datasets/movielens/ml-latest-small.zip).\n",
        "\n",
        "## Custom Code\n",
        "\n",
        "The custom packages; soft_impute and functionsCF will need to be installed"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the standard papackages\n",
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install fancyimpute"
      ],
      "metadata": {
        "id": "f5x_KMp8fpxo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad8ba29d-ebfe-4e22-9af8-21e7684a41c7"
      },
      "id": "f5x_KMp8fpxo",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.25.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Collecting fancyimpute\n",
            "  Downloading fancyimpute-0.7.0.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting knnimpute>=0.1.0 (from fancyimpute)\n",
            "  Downloading knnimpute-0.1.0.tar.gz (8.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn>=0.24.2 in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.2.2)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.4)\n",
            "Requirement already satisfied: cvxopt in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (1.3.2)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from fancyimpute) (7.4.4)\n",
            "Collecting nose (from fancyimpute)\n",
            "  Downloading nose-1.3.7-py3-none-any.whl (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from knnimpute>=0.1.0->fancyimpute) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.2->fancyimpute) (3.5.0)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (0.6.2.post8)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (2.0.13)\n",
            "Requirement already satisfied: scs>=1.1.6 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (3.2.4.post1)\n",
            "Requirement already satisfied: setuptools>65.5.1 in /usr/local/lib/python3.10/dist-packages (from cvxpy->fancyimpute) (67.7.2)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (24.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.5.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (1.2.1)\n",
            "Requirement already satisfied: tomli>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pytest->fancyimpute) (2.0.1)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.10/dist-packages (from osqp>=0.4.1->cvxpy->fancyimpute) (0.1.7.post2)\n",
            "Building wheels for collected packages: fancyimpute, knnimpute\n",
            "  Building wheel for fancyimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fancyimpute: filename=fancyimpute-0.7.0-py3-none-any.whl size=29881 sha256=93977ad265634880fc4dea13d01b989dc265eed56b3649e659a73c3a9f7b0deb\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/0c/d3/ee82d1fbdcc0858d96434af108608d01703505d453720c84ed\n",
            "  Building wheel for knnimpute (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for knnimpute: filename=knnimpute-0.1.0-py3-none-any.whl size=11330 sha256=5b78216e3a0978174af7dbe019cfa80d8f7c6a14cd989a5a088ea91bad2116a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/06/a5/45a724630562413c374e29c08732411d496092408b3a7bf754\n",
            "Successfully built fancyimpute knnimpute\n",
            "Installing collected packages: nose, knnimpute, fancyimpute\n",
            "Successfully installed fancyimpute-0.7.0 knnimpute-0.1.0 nose-1.3.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Collab Connection to Google Drive: External data: Local Files, Drive, Sheets, and Cloud Storage\n",
        "https://colab.research.google.com/notebooks/io.ipynb"
      ],
      "metadata": {
        "id": "cA4Pv9fGpe19"
      },
      "id": "cA4Pv9fGpe19"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "id": "AFNnBYR2hAEB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90c86d98-3f14-4c2b-973d-d732fe6393a0"
      },
      "id": "AFNnBYR2hAEB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# location of custom packages: soft_impute , functionsCF, and dataset ratings.csv\n",
        "# CollaborativeFiltering folder in google drive\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/Colab Notebooks/CollaborativeFiltering/')"
      ],
      "metadata": {
        "id": "IsIo2LkxhhQl"
      },
      "id": "IsIo2LkxhhQl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change the working directory\n",
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/CollaborativeFiltering/\")"
      ],
      "metadata": {
        "id": "qv7OvJ8nr0TU"
      },
      "id": "qv7OvJ8nr0TU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gdoHuVxfhj7P"
      },
      "id": "gdoHuVxfhj7P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GQ18Kd5F3uKe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c2c72cb-d95c-427e-9d56-0a873c26fcb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement functionsCF (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for functionsCF\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# !pip install functionsCF"
      ],
      "id": "GQ18Kd5F3uKe"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "e8ae0c8f",
      "metadata": {
        "id": "e8ae0c8f"
      },
      "outputs": [],
      "source": [
        "# Impute necessary packages\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from fancyimpute import BiScaler\n",
        "from soft_impute import SoftImpute\n",
        "# from fancyimpute import SoftImpute\n",
        "from functionsCF import GenerateTrainingSet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40bbbdd4",
      "metadata": {
        "id": "40bbbdd4"
      },
      "source": [
        "## Create the incomplete matrices for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read movielens data from files- point to where data is stored, small set of Movielens dataset\n",
        "# 100836 (rows), userId\tmovieId\trating\ttimestamp (columns).\n",
        "# Using smaller dataset rather than the full dataset to speed performance.\n",
        "# Your results may vary depending on which Movielens data set is used; Several are available online\n",
        "# read in values only\n",
        "rating = pd.read_csv('ratings.csv', sep=',').values"
      ],
      "metadata": {
        "id": "Vsbz4zO0j7DB"
      },
      "id": "Vsbz4zO0j7DB",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we only care about the ratings, so we only use the first three columns, which contain use IDs, movie IDs, and ratings.\n",
        "rating = rating[:,0:3]"
      ],
      "metadata": {
        "id": "ptTHCfTfxBuC"
      },
      "id": "ptTHCfTfxBuC",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show top 5 rows\n",
        "print(rating[:5, :])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-i471csu_K3",
        "outputId": "6a6bd682-16fb-4c16-9d33-91110740fcc3"
      },
      "id": "a-i471csu_K3",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 1.  1.  4.]\n",
            " [ 1.  3.  4.]\n",
            " [ 1.  6.  4.]\n",
            " [ 1. 44.  5.]\n",
            " [ 1. 47.  5.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "b23d947b",
      "metadata": {
        "id": "b23d947b"
      },
      "outputs": [],
      "source": [
        "# Use all known information to create the incomplete matrix\n",
        "\n",
        "# First, create an empty matrix\n",
        "matrix_incomplete = np.zeros((len(np.unique(rating[:,0])), len(np.unique(rating[:,1]))))\n",
        "\n",
        "# Second, Since some movies don't have any ratings, we only use the movies that have ratings.\n",
        "# Here we correspondingly change the movie IDs to make each column has ratings.\n",
        "# create an array of all movie IDs\n",
        "usedID = np.unique(rating[:, 1])\n",
        "# replace the movie IDs by the their positions in the array we just created\n",
        "for i in range(len(rating[:,1])):\n",
        "    rating[:,1][i] = np.where(usedID==rating[:,1][i])[0][0] + 1\n",
        "\n",
        "# Finally, we construct the incomplete matrix, on which the incomplete components are nan by\n",
        "# default.\n",
        "# all components are nan by default\n",
        "matrix_incomplete[:] = np.nan\n",
        "# create the index pair of the components with ratings\n",
        "indices = np.array(rating[:,0] - 1).astype(int), np.array(rating[:,1] - 1).astype(int)\n",
        "# change the values in the corresponding positions to the known rating information\n",
        "matrix_incomplete[indices] = rating[:,2]"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SxkFcoFMfyRY",
        "outputId": "06b371b7-e792-43ce-8e8f-97c02cea7ba5"
      },
      "id": "SxkFcoFMfyRY",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([  0,   0,   0, ..., 609, 609, 609]),\n",
              " array([   0,    2,    5, ..., 9444, 9445, 9485]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GHQo1Jpff5fb"
      },
      "outputs": [],
      "source": [
        "# Use all known information to create the incomplete matrix\n",
        "\n",
        "# First, create an empty matrix\n",
        "matrix_incomplete = np.zeros((len(np.unique(rating[:,0])), len(np.unique(rating[:,1]))))\n",
        "\n",
        "# Second, Since some movies don't have any ratings, we only use the movies that have ratings.\n",
        "# Here we correspondingly change the movie IDs to make each column has ratings.\n",
        "# create an array of all movie IDs\n",
        "usedID = np.unique(rating[:, 1])\n",
        "# replace the movie IDs by the their positions in the array we just created\n",
        "for i in range(len(rating[:,1])):\n",
        "    rating[:,1][i] = np.where(usedID==rating[:,1][i])[0][0] + 1\n",
        "\n",
        "# Finally, we construct the incomplete matrix, on which the incomplete components are nan by\n",
        "# default.\n",
        "# all components are nan by default\n",
        "matrix_incomplete[:] = np.nan\n",
        "# create the index pair of the components with ratings\n",
        "indices = np.array(rating[:,0] - 1).astype(int), np.array(rating[:,1] - 1).astype(int)\n",
        "# change the values in the corresponding positions to the known rating information\n",
        "matrix_incomplete[indices] = rating[:,2]"
      ],
      "id": "GHQo1Jpff5fb"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2f54b0e6",
      "metadata": {
        "id": "2f54b0e6"
      },
      "outputs": [],
      "source": [
        "# Obtain the index pairs of the training set and the validation set, with ratio 90%\n",
        "train_indices, validation_indices = GenerateTrainingSet(rating[:,0], rating[:,1], 0.90)\n",
        "# And then use the index pairs to create the incomplete training test\n",
        "matrix_train = matrix_incomplete.copy()\n",
        "matrix_train[:] = np.nan\n",
        "matrix_train[train_indices] = matrix_incomplete[train_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69a998c9",
      "metadata": {
        "id": "69a998c9"
      },
      "source": [
        "##  Run the softImpute model for collaborative filtering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0d16d1db",
      "metadata": {
        "id": "0d16d1db"
      },
      "outputs": [],
      "source": [
        "# Create the BiScaler model\n",
        "biscaler = BiScaler(scale_rows=False, scale_columns=False, max_iters=50, verbose=False)\n",
        "# Rescale both rows and columns to have zero mean\n",
        "matrix_train_normalized = biscaler.fit_transform(matrix_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ae5de031",
      "metadata": {
        "id": "ae5de031"
      },
      "outputs": [],
      "source": [
        "# Use softImpute to complete the matrix. J means the number of archetypes and rand_seed means the\n",
        "# seed for the inner random number generator, verbose control whether outputting algorithm logs.\n",
        "softImpute = SoftImpute(J = 4, maxit = 200, random_seed = 1, verbose = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "19484161",
      "metadata": {
        "id": "19484161"
      },
      "outputs": [],
      "source": [
        "# Run the softImpute model on the normalized training set\n",
        "matrix_train_softImpute = softImpute.fit(matrix_train_normalized)\n",
        "# Use the softImpute model to create the predicted matrix. If we set copyto as True, then it\n",
        "# directly change the value of matrix_train_normalized\n",
        "matrix_train_filled_normalized = matrix_train_softImpute.predict(matrix_train_normalized, copyto = False)\n",
        "# Inverse transformation to undo the scaling\n",
        "matrix_train_filled = biscaler.inverse_transform(matrix_train_filled_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9481eb67",
      "metadata": {
        "id": "9481eb67"
      },
      "source": [
        "## Analysis of the predicted ratings"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "988d616f",
      "metadata": {
        "id": "988d616f"
      },
      "source": [
        "### Out-of-sample R^2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "a097cfe2",
      "metadata": {
        "id": "a097cfe2"
      },
      "outputs": [],
      "source": [
        "# Create the baseline method\n",
        "train_average = np.average(matrix_train[train_indices])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "d89639dd",
      "metadata": {
        "id": "d89639dd",
        "outputId": "a24afeb6-5248-4b4b-a8f6-87bdace3725e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "out-of-sample R2: 0.2131, in-sample R2: 0.6279.\n"
          ]
        }
      ],
      "source": [
        "# Calculate out-of-sample R2 and in-sample R2\n",
        "# Your results may vary from the lesson due to datasize and training test split.\n",
        "validation_mse = ((matrix_train_filled[validation_indices] - matrix_incomplete[validation_indices]) ** 2).mean()\n",
        "training_mse = ((matrix_train_filled[train_indices] - matrix_incomplete[train_indices]) ** 2).mean()\n",
        "validation_mse_baseline = ((train_average - matrix_incomplete[validation_indices]) ** 2).mean()\n",
        "training_mse_baseline = ((train_average - matrix_incomplete[train_indices]) ** 2).mean()\n",
        "print(\"out-of-sample R2: %.4f, in-sample R2: %.4f.\" % (1 - validation_mse / validation_mse_baseline, 1 - training_mse / training_mse_baseline))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d09890c5",
      "metadata": {
        "id": "d09890c5"
      },
      "source": [
        "### Get low-rank factors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "78125afd",
      "metadata": {
        "id": "78125afd",
        "outputId": "50ec2976-2de5-4ce7-f515-9d99455af861",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.13368601e-02, -9.55727094e-03,  1.07486072e-02,\n",
              "        -2.96418456e-03],\n",
              "       [-1.11172626e-02,  1.28758755e-03,  3.73951122e-03,\n",
              "        -1.51201687e-05],\n",
              "       [ 2.72721976e-03,  1.75416019e-04, -8.36824378e-03,\n",
              "        -2.46575422e-03],\n",
              "       ...,\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00],\n",
              "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00,\n",
              "         0.00000000e+00]])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Obtain the ratings of each archetype\n",
        "# Each row of this matrix corresponds to a song and each column corresponds to an archetype\n",
        "softImpute.v"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "1c37024e",
      "metadata": {
        "id": "1c37024e",
        "outputId": "913dc7c4-d30f-46f0-edc9-225212d5e08f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9724, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "softImpute.v.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "6250e638",
      "metadata": {
        "id": "6250e638",
        "outputId": "64542234-638d-45a7-9bd6-31718ae5bf2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-16.77927695,  -8.03958551, -13.00695311,   3.62963363],\n",
              "       [ -2.89136851,  17.07796106,  15.95694839,   1.14432509],\n",
              "       [-22.46168613,  64.76631443,  18.07508482,  31.06857691],\n",
              "       ...,\n",
              "       [ 24.55058805,  20.12788804,   2.14644389,  36.90772316],\n",
              "       [ -4.68379247,   8.12481631,  -3.69621525,  -5.01820993],\n",
              "       [ 19.44542258,  -4.41537808,   0.61585942, -17.28291418]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# (Optional)\n",
        "# Obtain the weights of archetypes of each user\n",
        "# each row of this matrix corresponds to a user and each column corresponds to an archetype\n",
        "weights = np.dot(softImpute.u, np.diagflat(softImpute.d).T)\n",
        "weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "c3dd121c",
      "metadata": {
        "id": "c3dd121c",
        "outputId": "fd9f9f53-e337-4761-89d2-14e45f066cfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(610, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "weights.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "cf2f7437",
      "metadata": {
        "id": "cf2f7437"
      },
      "outputs": [],
      "source": [
        "# And then the predicted matrix is computed by the product of two low-rank matrices\n",
        "new_prediction = np.dot(weights, softImpute.v.T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "d7421f9c",
      "metadata": {
        "id": "d7421f9c",
        "outputId": "7580c765-4ffd-4bdf-93b3-6b7def0579ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7.389340229675164e-11"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "# We can see it is the same with the output of the codes in the previous section\n",
        "np.sum(np.abs(new_prediction - matrix_train_filled_normalized))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0831b6a",
      "metadata": {
        "id": "c0831b6a"
      },
      "source": [
        "end of the note"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}